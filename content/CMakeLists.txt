### This file is automatically generated by Qt Design Studio.
### Do not change

qt_add_library(content STATIC)
find_package(llama REQUIRED PATHS ${LLAMA_LIB_DIR})

qt6_add_qml_module(content
    URI "content"
    VERSION 1.0
    RESOURCE_PREFIX "/qt/qml"
    QML_FILES
        App.qml
        Screen01.ui.qml
        ChatView.qml
        ChatInputField.qml
    RESOURCES
        fonts/fonts.txt
    SOURCES
        chatmessagemodel.cpp
        chatmessagemodel.h
        llamachatengine.h
        llamachatengine.cpp
        llamaresponsegenerator.h
        llamaresponsegenerator.cpp
)
target_link_libraries(content PRIVATE
    llama
)
add_custom_command(
    TARGET content POST_BUILD
    COMMAND ${CMAKE_COMMAND} -E copy_if_different
        "${CMAKE_CURRENT_LIST_DIR}/llama_models/Llama-3.1-8B-Open-SFT.Q4_K_M.gguf"
        "$<TARGET_FILE_DIR:QllamaTalkApp>"
    COMMENT "Copying Llama-3.1-8B-Open-SFT.Q4_K_M.gguf next to the QllamaTalkApp binary"
)
